
# 🤖 Unidad 1. Machine Learning Basado en el Análisis de Datos

Esta unidad introduce los conceptos fundamentales del Machine Learning (ML), su flujo de trabajo, las herramientas clave de la biblioteca `scikit-learn` de Python, y las metodologías esenciales para la preparación, división y preprocesamiento de datos.

---

### 1.1. ¿Qué es el Machine Learning?

[cite_start]El Machine Learning (ML) se define como un campo de estudio que utiliza modelos estadísticos para aprender de los datos[cite: 91]. [cite_start]Un aspecto clave es que modelos relativamente simples pueden realizar predicciones complejas[cite: 92].

#### Definiciones Clave

* [cite_start]**Definición temprana (Samuel, 1959):** "Programar computadoras para que aprendan de la experiencia debería eliminar la necesidad de gran parte de este esfuerzo de programación detallado"[cite: 111].
* [cite_start]**Definición moderna (Mitchell, 1997):** "Se dice que un programa de computadora aprende de la **experiencia E** con respecto a alguna clase de **tareas T** y una medida de **rendimiento P**, si su rendimiento en las tareas T, medido por P, mejora con la experiencia E"[cite: 114].
* **Definición matemática (Ej. Regresión Lineal):** Un modelo matemático que intenta encontrar la relación óptima entre variables. [cite_start]Por ejemplo, predecir ventas (Target, $y$) basándose en gastos de publicidad (Feature, $x$)[cite: 130]. [cite_start]El modelo $y = wx + b$ aprende los **parámetros** $w$ (peso) y $b$ [cite: 137] [cite_start]iterando desde valores arbitrarios ($f_1$) hasta un valor óptimo ($f_3$) que minimiza el error [cite: 142-144].

#### ML y Otros Campos
[cite_start]El Machine Learning está profundamente interconectado con otros campos[cite: 167]:
* [cite_start]Es un subcampo de la **Inteligencia Artificial**[cite: 160].
* [cite_start]**Deep Learning** es un subcampo del Machine Learning[cite: 163].
* [cite_start]Se solapa significativamente con **Estadística**, **Minería de Datos** y **Reconocimiento de Patrones**[cite: 154, 155, 159].

#### Tipos de Machine Learning
[cite_start]Según el método de supervisión, el ML se divide en[cite: 197]:
1.  [cite_start]**Supervisado:** Se proporciona un patrón objetivo (datos etiquetados)[cite: 199, 207]. [cite_start]El capítulo se centra en este tipo [cite: 244][cite_start], que incluye algoritmos como Regresión Lineal, Regresión Logística, Árboles de Decisión, KNN, SVM y Redes Neuronales[cite: 244].
2.  [cite_start]**No Supervisado:** El patrón objetivo debe ser descubierto (datos no etiquetados)[cite: 200, 208]. [cite_start]Incluye Clustering, PCA y Análisis de Asociación[cite: 244].
3.  [cite_start]**Refuerzo:** Se aprende mediante la optimización de políticas (recompensas y castigos)[cite: 206, 209].

#### Flujo de Trabajo del Machine Learning
[cite_start]El proceso general para construir un modelo de ML es[cite: 215]:
1.  [cite_start]**Definición del Problema:** Comprender el objetivo de negocio[cite: 222, 225].
2.  [cite_start]**Preparación de Datos:** Recolección de datos brutos (Raw Data) [cite: 228, 231] [cite_start]y preprocesamiento[cite: 223, 226].
3.  [cite_start]**Machine Learning (Modelado):** Se divide la data en conjuntos de **Train** (Entrenamiento) [cite: 224][cite_start], **Validate** (Validación) [cite: 229] [cite_start]y **Test** (Prueba)[cite: 230].
4.  [cite_start]**Entrenamiento y Evaluación:** Esta fase incluye **Ingeniería de características** (Feature engineering) [cite: 235][cite_start], **Modelado y optimización** (entrenar el modelo con los datos) [cite: 236-237][cite_start], y **Evaluación de rendimiento** (Performance metrics) [cite: 238-239].
5.  [cite_start]**Aplicación:** Aplicar el modelo en la vida real[cite: 232].

#### Parámetros vs. Hiperparámetros
* [cite_start]**Parámetros:** Se aprenden *desde los datos* durante el entrenamiento[cite: 261]. [cite_start]Contienen el patrón de los datos [cite: 262] [cite_start](ej. $w$ y $b$ en regresión lineal [cite: 263][cite_start], pesos de una red neuronal [cite: 264]).
* [cite_start]**Hiperparámetros:** Se configuran *manualmente* por el practicante *antes* del entrenamiento[cite: 266]. [cite_start]Se "afinan" (tunan) para optimizar el rendimiento [cite: 267] [cite_start](ej. el valor $k$ en KNN [cite: 268][cite_start], la tasa de aprendizaje [cite: 269][cite_start], la profundidad máxima de un árbol [cite: 270]).

---

### 1.2. Biblioteca Python scikit-learn

[cite_start]`scikit-learn` es la biblioteca de ML más representativa de Python[cite: 357].

#### Características
* [cite_start]Proporciona una interfaz de biblioteca integrada y unificada[cite: 300].
* [cite_start]Incluye una amplia variedad de algoritmos de ML, funciones de preprocesamiento y selección de modelos[cite: 305].
* [cite_start]Es simple, eficiente y está construida sobre **NumPy, SciPy y matplotlib**[cite: 307].
* [cite_start]Es de código abierto y puede usarse comercialmente[cite: 311].
* [cite_start]**No soporta GPU**[cite: 310].

#### Mecanismo de `scikit-learn`
[cite_start]El flujo de trabajo de la API de `scikit-learn` es intuitivo y sigue tres pasos[cite: 323]:
1.  [cite_start]**Instance:** Crear una instancia del objeto del modelo (Estimator)[cite: 325].
2.  [cite_start]**Fit:** Entrenar el modelo con los datos[cite: 326].
3.  [cite_start]**Predict / transform:** Usar el modelo entrenado para hacer predicciones o transformar datos[cite: 327].



#### Estimator, Classifier y Regressor
* **`Estimator`:** El objeto base. [cite_start]Aprende de los datos usando el método `.fit()` [cite: 343] [cite_start]y puede hacer predicciones usando `.predict()`[cite: 339, 343].
* [cite_start]**`Classifier`:** Un estimador para tareas de clasificación (ej. `DecisionTreeClassifier`, `KNeighborsClassifier`) [cite: 340, 344-345].
* [cite_start]**`Regressor`:** Un estimador para tareas de regresión (predicción numérica) (ej. `LinearRegression`, `KNeighborsRegressor`) [cite: 340, 346-347].

#### Sintaxis Básica de `scikit-learn`
* [cite_start]**Importar un estimador:** [cite: 358-359]
    [cite_start]`from sklearn.linear_model import LinearRegression` [cite: 360]
* **Importar un preprocesador:**
    [cite_start]`from sklearn.preprocessing import StandardScaler` [cite: 381]
* **Importar división de datos:**
    [cite_start]`from sklearn.model_selection import train_test_split` [cite: 493]
* **Importar métricas:**
    [cite_start]`from sklearn import metrics` [cite: 384]

* [cite_start]**Instanciar (con hiperparámetros):** [cite: 363]
    [cite_start]`myModel = KNeighborsClassifier(n_neighbors=10)` [cite: 364]
* [cite_start]**Dividir los datos (Hold-out):** [cite: 382]
    [cite_start]`X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)` [cite: 383]
* [cite_start]**Entrenar el modelo (Supervisado):** [cite: 378]
    `myModel.fit(X_train, Y_train)`
* [cite_start]**Hacer predicciones:** [cite: 380]
    `Y_pred = myModel.predict(X_test)`
* [cite_start]**Evaluar el rendimiento:** [cite: 384]
    `metrics.accuracy_score(Y_test, Y_pred)`
* [cite_start]**Afinar hiperparámetros (con Cross-Validation):** [cite: 385]
    [cite_start]`myGridCV = GridSearchCV(estimator, parameter_grid, cv=5)` [cite: 386]

#### Ejemplo Práctico: Estandarización
[cite_start]El preprocesamiento, como la **estandarización**, es crucial para mejorar el rendimiento[cite: 769]. [cite_start]La estandarización (o *z-transformation*) [cite: 773] [cite_start]convierte los datos para que sigan una distribución normal estándar [cite: 772][cite_start], usando la fórmula $z = \frac{x - m}{\sigma}$ (donde $m$ es la media y $\sigma$ la desviación estándar)[cite: 776].

[cite_start]En `scikit-learn`, se usa `StandardScaler`[cite: 777]:
1.  [cite_start]**Importar:** `from sklearn.preprocessing import StandardScaler` [cite: 786, 927]
2.  [cite_start]**Instanciar:** `scaler = StandardScaler()` [cite: 787, 930]
3.  **Ajustar (Fit):** Se aprende la media ($m$) y la desviación ($\sigma$) **solo de los datos de entrenamiento**:
    [cite_start]`scaler.fit(X_train)` [cite: 837, 932]
4.  [cite_start]**Transformar:** Se aplica la transformación a los datos de entrenamiento y prueba[cite: 926]:
    [cite_start]`X_train = scaler.transform(X_train)` [cite: 839, 933]
    `X_test = scaler.transform(X_test)`
5.  [cite_start]**`fit_transform`:** Se pueden combinar los pasos 3 y 4 (solo para `X_train`)[cite: 1063]:
    `X_train = scaler.fit_transform(X_train)`

[cite_start]Antes de la estandarización, las columnas pueden tener rangos de valores muy diferentes[cite: 880]. [cite_start]Después, todos los valores están centrados alrededor de 0, lo que ayuda a muchos algoritmos a converger mejor[cite: 915].

#### [cite_start]Módulos Principales de `scikit-learn` [cite: 1096, 1109]

| Módulo | Función Principal | Ejemplos |
| :--- | :--- | :--- |
| `sklearn.datasets` | [cite_start]Cargar datasets de ejemplo[cite: 1102]. | `load_iris()`, `load_breast_cancer()` |
| `sklearn.preprocessing` | [cite_start]Preprocesamiento de datos (escalado, codificación)[cite: 1102]. | `StandardScaler`, `LabelEncoder`, `OneHotEncoder` |
| `sklearn.model_selection` | [cite_start]División de datos, validación y afinado de hiperparámetros[cite: 1102]. | `train_test_split`, `GridSearchCV`, `KFold` |
| `sklearn.metrics` | [cite_start]Evaluación de rendimiento del modelo[cite: 1102]. | `accuracy_score`, `precision_score`, `recall_score`, `roc_auc_score` |
| `sklearn.linear_model` | [cite_start]Algoritmos lineales[cite: 1110]. | `LinearRegression`, `LogisticRegression` |
| `sklearn.tree` | [cite_start]Algoritmos de Árboles de Decisión[cite: 1110]. | `DecisionTreeClassifier` |
| `sklearn.neighbors` | [cite_start]Algoritmos de vecinos cercanos[cite: 1110]. | `KNeighborsClassifier` (K-NN) |
| `sklearn.svm` | [cite_start]Support Vector Machine (Máquinas de Vectores de Soporte)[cite: 1110]. | `SVC` |
| `sklearn.ensemble` | [cite_start]Algoritmos de Ensamblado (Ensemble)[cite: 1110]. | `RandomForestClassifier`, `AdaBoostClassifier` |
| `sklearn.cluster` | [cite_start]Algoritmos de clustering (No supervisado)[cite: 1110]. | `KMeans`, `DBSCAN` |
| `sklearn.pipeline` | [cite_start]Herramienta para encadenar pasos de preprocesamiento y modelado[cite: 1110]. | `Pipeline` |

---

### 1.3. Preparación y División del Dataset

[cite_start]La división de datos es fundamental para evaluar un modelo de ML[cite: 1146]. [cite_start]El conjunto de datos general se divide en un conjunto de **entrenamiento** y uno de **evaluación (prueba)**[cite: 1162, 1165, 1168].

#### Overfitting (Sobreajuste) y Generalización
* [cite_start]**Generalización:** Es la capacidad del modelo para predecir con precisión datos nuevos que no ha visto antes[cite: 1190].
* [cite_start]**Overfitting:** Ocurre cuando un modelo se ajusta *demasiado* a los datos de entrenamiento, aprendiendo incluso el ruido[cite: 1189, 1260].
* [cite_start]**Underfitting (Subajuste):** Ocurre cuando un modelo es *demasiado simple* (baja capacidad) y no puede capturar el patrón subyacente de los datos[cite: 1239].



> [cite_start]**El Dilema:** A medida que aumenta la complejidad (flexibilidad) del modelo[cite: 1283]:
> [cite_start]* El error en el **conjunto de entrenamiento** (Training set) siempre disminuye[cite: 1301].
> [cite_start]* El error en el **conjunto de prueba** (Test set) disminuye al principio, pero luego comienza a *aumentar*[cite: 1302]. [cite_start]El punto donde el error de prueba empieza a subir es donde comienza el overfitting[cite: 1303].

[cite_start]El conjunto de prueba es **esencial** [cite: 1305] para detectar el overfitting y seleccionar un modelo que generalice bien.

#### Cross-Validation (Validación Cruzada)
[cite_start]El conjunto de prueba (Test set) debe usarse **¡solo una vez!** al final, para la evaluación final[cite: 1320].

[cite_start]Para evaluar el modelo *durante* el entrenamiento (por ejemplo, para afinar hiperparámetros [cite: 1329]), necesitamos una forma de simular un "conjunto de prueba" sin tocar el real. [cite_start]Para esto, dividimos el **conjunto de entrenamiento** (Training Data) [cite: 1324] [cite_start]en dos partes más pequeñas: un nuevo conjunto de `Train` [cite: 1323] [cite_start]y un conjunto de `Cross Validate` (Validación)[cite: 1322, 1325].

**Método: k-Fold Cross-Validation**
[cite_start]Es el método más común[cite: 1383, 1387]:
1.  [cite_start]Se subdivide el conjunto de entrenamiento (original) en *k* partes iguales (folds)[cite: 1361]. [cite_start](Usualmente k=10 [cite: 1390]).
2.  [cite_start]Se itera *k* veces (rondas) [cite: 1391, 1394-1402].
3.  [cite_start]En cada ronda, se usa 1 fold como conjunto de **validación** y los *k-1* folds restantes como conjunto de **entrenamiento** [cite: 1361-1366, 1395-1419].
4.  [cite_start]Se calcula la métrica de rendimiento (ej. accuracy) en cada ronda [cite: 1420-1422].
5.  [cite_start]El rendimiento final del modelo es el **promedio** de las métricas de las *k* rondas[cite: 1423].



**Método: Leave One Out (LOO)**
[cite_start]Es un caso extremo de k-Fold donde $k$ es igual al número total de muestras[cite: 1376]. [cite_start]Se entrena con todos los datos menos uno, y se valida con ese único dato [cite: 1378-1379]. [cite_start]Es computacionalmente muy costoso[cite: 1376].

---

### 1.4. Preprocesamiento de Datos

Preparar los datos es vital para un buen modelo. [cite_start]Esto incluye la limpieza (manejo de valores atípicos y faltantes) [cite: 1452] y la transformación (escalado y codificación).

#### Manejo de Valores Faltantes (Missing Values)
[cite_start]Los valores faltantes (identificados en Python como `np.nan` [cite: 1610] [cite_start]o `NaN` [cite: 1642]) deben ser tratados.

**1. Identificación:**
[cite_start]Se pueden contar usando `df.isnull().sum()`[cite: 1656, 1661].

**2. [cite_start]Eliminación (con Pandas `dropna()`):** [cite: 1684]
* [cite_start]`df.dropna()`: Elimina cualquier **fila** que contenga al menos un `NaN` (eje por defecto 0)[cite: 1685, 1694].
* [cite_start]`df.dropna(axis=1)`: Elimina cualquier **columna** que contenga un `NaN`[cite: 1743].
* [cite_start]`df.dropna(how='all')`: Elimina filas/columnas donde **todos** los valores son `NaN`[cite: 1759, 1794].
* [cite_start]`df.dropna(thresh=N)`: Mantiene las filas que tienen al menos `N` valores no-`NaN`[cite: 1811, 1829].
* [cite_start]`df.dropna(subset=['col_name'])`: Elimina filas que tienen `NaN` específicamente en la columna 'col\_name'[cite: 1845, 1849].

**3. Imputación (Relleno):**
[cite_start]Se usa cuando eliminar datos resultaría en una pérdida significativa de información[cite: 1868].
* [cite_start]**Métodos simples:** Rellenar con un valor (ej. 'unknown' [cite: 1563][cite_start]), la media, la mediana o el valor más frecuente (moda) de la columna[cite: 1563, 1870].
* [cite_start]**Con `scikit-learn` (`SimpleImputer`):** Es el método preferido[cite: 1871].
    * [cite_start]`from sklearn.impute import SimpleImputer` [cite: 1872]
    * [cite_start]`impt = SimpleImputer(strategy='mean')` [cite: 1874] [cite_start](Estrategias: 'mean', 'median', 'most_frequent' [cite: 1926]).
    * [cite_start]`impt.fit(X_train)`[cite: 1912]: Aprende la media (o mediana/moda) del set de entrenamiento.
    * [cite_start]`X_train_imputed = impt.transform(X_train)`: Aplica la imputación[cite: 1915].
    * [cite_start]`X_test_imputed = impt.transform(X_test)`: Aplica la *misma* imputación (con la media de train) al set de prueba[cite: 1946].

#### Manejo de Datos Categóricos
Los algoritmos de ML requieren entradas numéricas. [cite_start]Los datos categóricos deben ser convertidos[cite: 2000].

**1. [cite_start]Datos Ordinales (con orden):** [cite: 1967]
Ej. Tallas: 'M' < 'L' < 'XL'.
[cite_start]Se deben mapear a enteros que respeten ese orden [cite: 1986-1987].
* [cite_start]`size_mapping = {'M': 1, 'L': 2, 'XL': 3}` [cite: 2001-2003]
* [cite_start]`df['size'] = df['size'].map(size_mapping)` [cite: 2029]

**2. Datos Nominales (sin orden) y Etiquetas de Clase:**
Ej. [cite_start]Colores: 'red', 'green', 'blue' [cite: 1986] o Etiquetas: 'setosa', 'versicolor'.

* **Codificación de Etiquetas (Label Encoding):**
    [cite_start]Convierte cada etiqueta única en un entero (ej. 'class1': 0, 'class2': 1)[cite: 2057]. [cite_start]Se usa `LabelEncoder` de `scikit-learn`[cite: 2120].
    * [cite_start]`from sklearn.preprocessing import LabelEncoder` [cite: 2138]
    * [cite_start]`enc = LabelEncoder()` [cite: 2139]
    * [cite_start]`y_encoded = enc.fit_transform(df['classlabel'])` [cite: 2140]

* [cite_start]**One-Hot Encoding (para características nominales):** [cite: 2159]
    Usar `LabelEncoder` para características (X) es incorrecto, ya que crea un orden artificial. [cite_start]Se debe usar **One-Hot Encoding**[cite: 2164].
    [cite_start]Crea nuevas columnas "dummy" (0 o 1) para cada categoría, indicando presencia (1) o ausencia (0) [cite: 2162-2163].
    * [cite_start]**Método Pandas:** `pd.get_dummies(df['species'])` [cite: 2232-2233].
    * [cite_start]**Método `scikit-learn`:** `OneHotEncoder`[cite: 2247, 2261]. [cite_start]Este método es preferido en pipelines y a menudo devuelve una **matriz dispersa** (sparse matrix) [cite: 2247-2248] para ahorrar memoria, ya que la mayoría de los valores serán 0.

#### División de Datos Estratificada (Stratify)
Al usar `train_test_split`, si el dataset está desbalanceado (ej. 90% clase A, 10% clase B), una división aleatoria simple podría resultar en un set de prueba sin muestras de la clase B.
* [cite_start]**Solución:** Usar el parámetro `stratify=y`[cite: 2384].
* [cite_start]Esto asegura que la proporción de las clases (ej. 90/10) se mantenga *idéntica* tanto en el conjunto de entrenamiento como en el de prueba, reflejando el dataset original[cite: 2384].

#### Tópicos Avanzados: Tradeoff de Sesgo-Varianza y Regularización
* **Tradeoff de Sesgo-Varianza:**
    * [cite_start]**Sesgo (Bias):** Error por suposiciones incorrectas (Underfitting)[cite: 2388].
    * [cite_start]**Varianza (Variance):** Error por sensibilidad excesiva a los datos de entrenamiento (Overfitting)[cite: 2388].
    * **Error Total $\approx$ Sesgo² + Varianza**. [cite_start]El objetivo es encontrar la complejidad óptima que minimice este error total[cite: 2389].
* **Regularización:** Técnica para prevenir el overfitting en modelos lineales penalizando coeficientes (pesos) grandes.
    * [cite_start]**Ridge (L2):** Añade una penalización $\lambda\sum{w_j^2}$[cite: 2390, 2392]. Encoge los pesos, pero no los hace cero.
    * [cite_start]**Lasso (L1):** Añade una penalización $\lambda\sum{|w_j|}$[cite: 2393, 2394]. Puede forzar que algunos pesos sean exactamente cero, realizando una selección de características automática.
    * [cite_start]**ElasticNet:** Combina penalizaciones L1 y L2[cite: 2395].

---

### 1.5. Práctica: Solución de Problemas con scikit-learn (Ej. Iris)

[cite_start]Esta sección aplica todos los conceptos anteriores en un caso práctico completo usando el dataset "Iris"[cite: 2398].

#### 1. Entendimiento del Problema y Datos (EDA)
* [cite_start]**Objetivo:** Clasificar la especie de una flor Iris (Target)[cite: 2398].
* [cite_start]**Clases (Target):** 3 especies (Setosa, Versicolor, Virginica)[cite: 2410].
* [cite_start]**Características (Features):** `sepal_length`, `sepal_width`, `petal_length`, `petal_width`[cite: 2400, 2409].
* **Análisis de Datos:**
    * [cite_start]Se cargan los datos y se convierten a un DataFrame de Pandas[cite: 2404].
    * **Valores Faltantes:** Se comprueba con `iris.isnull().sum()`. [cite_start]No se encontraron[cite: 2411].
    * [cite_start]**Distribución de Clases:** Se comprueba con `iris.groupby('target').size()`[cite: 2418]. [cite_start]Hay 50 muestras de cada clase (33.3% cada una)[cite: 2418, 2434]. Es un **dataset balanceado**.
    * [cite_start]**Estadísticas y Correlación:** `iris.describe()` [cite: 2413] [cite_start]y `iris.corr()`[cite: 2416]. [cite_start]Se observa que `petal_length` y `petal_width` están altamente correlacionados (0.96) [cite: 2416][cite_start], sugiriendo un problema de multicolinealidad[cite: 2417].
    * [cite_start]**Visualización:** Se usan `pairplot` [cite: 2429] y `heatmap` para confirmar visualmente las relaciones y la alta correlación.

#### 2. División y Preparación de Datos
* **Separación X/y:** Se separan las características (X) del objetivo (y).
* **División Train/Test:** Se usa `train_test_split` (ej. 80% train, 20% test).
* **Validación Cruzada:**
    * [cite_start]Se muestra cómo usar `KFold` (CV estándar) [cite: 2442] [cite_start]y `StratifiedKFold` (CV estratificada)[cite: 2444].
    * [cite_start]`StratifiedKFold` es preferible porque mantiene la distribución 33/33/33 de las clases en cada fold, asegurando que la validación sea representativa[cite: 2444].

#### 3. Selección y Evaluación del Modelo
* **Curva de Aprendizaje (`Learning Curve`):**
    [cite_start]Se usa para diagnosticar bias vs. variance[cite: 2450]. Muestra el rendimiento del modelo a medida que ve más datos de entrenamiento.
* **Afinado de Hiperparámetros (`GridSearchCV`):**
    [cite_start]Se utiliza para encontrar la mejor combinación de hiperparámetros (ej. `criterion`, `max_depth` para un `DecisionTreeClassifier`) probando todas las combinaciones posibles mediante validación cruzada[cite: 2454].

#### 4. Métricas de Evaluación (Clasificación)
Una vez que el modelo (`GridSearchCV`) está entrenado y se hacen predicciones sobre el `X_test`, se evalúa el rendimiento.

* [cite_start]**Matriz de Confusión (`Confusion Matrix`):** [cite: 2461]
    Es la base para todas las métricas. Compara los valores reales (True label) con los predichos (Predicted label).
    * [cite_start]**TP (True Positive):** Real = 1, Predicho = 1[cite: 2463].
    * [cite_start]**FN (False Negative):** Real = 1, Predicho = 0[cite: 2463].
    * [cite_start]**FP (False Positive):** Real = 0, Predicho = 1[cite: 2463].
    * [cite_start]**TN (True Negative):** Real = 0, Predicho = 0[cite: 2463].

* **Métricas Clave:**
    * [cite_start]**Accuracy (Exactitud):** $\frac{TP + TN}{Total}$[cite: 2471]. Proporción de predicciones correctas. (Usar con cuidado en datasets desbalanceados).
    * [cite_start]**Precision (Precisión):** $\frac{TP}{TP + FP}$[cite: 2464]. De los que *dijimos* que eran positivos, ¿cuántos acertamos?.
    * [cite_start]**Recall (Sensibilidad o TPR):** $\frac{TP}{TP + FN}$[cite: 2466, 2473]. De *todos los positivos reales*, ¿cuántos encontramos?.
    * [cite_start]**F1-Score:** La media armónica de Precision y Recall[cite: 2468]. Es una métrica excelente para datasets desbalanceados. [cite_start]$F_1 = 2 \frac{Precision \times Recall}{Precision + Recall}$[cite: 2468].
    * [cite_start]**FPR (Tasa de Falsos Positivos):** $\frac{FP}{FP + TN}$[cite: 2473]. Proporción de negativos reales que clasificamos incorrectamente como positivos.

* **Curva ROC y AUC:**
    * **Curva ROC:** Gráfica que muestra el rendimiento de un clasificador en todos los umbrales de clasificación. [cite_start]Muestra **TPR** (Eje Y) vs. **FPR** (Eje X)[cite: 2475].
    * **AUC (Area Under the Curve):** El área bajo la curva ROC. Es una métrica única que resume el rendimiento del modelo.
        * AUC = 1.0: Clasificador perfecto.
        * [cite_start]AUC = 0.5: Clasificador inútil (aleatorio)[cite: 2476].
        * [cite_start]Un AUC de 0.85 o más se considera bueno[cite: 2476].

#### 5. Predicción Final
* [cite_start]Se carga el modelo final (el mejor `estimator_` encontrado por `GridSearchCV`)[cite: 2478].
* [cite_start]Se realizan las predicciones finales sobre el conjunto de prueba (`X_test`)[cite: 2479].
* [cite_start]Los resultados se guardan, por ejemplo, en un archivo CSV[cite: 2480].

---

📅 **Fecha de creación:** 27/10/2025  
✍️ **Autor:** Fran García

