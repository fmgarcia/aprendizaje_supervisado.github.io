
#  Unidad 1. Machine Learning Basado en el An谩lisis de Datos

Esta unidad introduce los conceptos fundamentales del Machine Learning (ML), su flujo de trabajo, las herramientas clave de la biblioteca `scikit-learn` de Python, y las metodolog铆as esenciales para la preparaci贸n, divisi贸n y preprocesamiento de datos.

---

### 1.1. 驴Qu茅 es el Machine Learning?

[cite_start]El Machine Learning (ML) se define como un campo de estudio que utiliza modelos estad铆sticos para aprender de los datos[cite: 91]. [cite_start]Un aspecto clave es que modelos relativamente simples pueden realizar predicciones complejas[cite: 92].

#### Definiciones Clave

* [cite_start]**Definici贸n temprana (Samuel, 1959):** "Programar computadoras para que aprendan de la experiencia deber铆a eliminar la necesidad de gran parte de este esfuerzo de programaci贸n detallado"[cite: 111].
* [cite_start]**Definici贸n moderna (Mitchell, 1997):** "Se dice que un programa de computadora aprende de la **experiencia E** con respecto a alguna clase de **tareas T** y una medida de **rendimiento P**, si su rendimiento en las tareas T, medido por P, mejora con la experiencia E"[cite: 114].
* **Definici贸n matem谩tica (Ej. Regresi贸n Lineal):** Un modelo matem谩tico que intenta encontrar la relaci贸n 贸ptima entre variables. [cite_start]Por ejemplo, predecir ventas (Target, $y$) bas谩ndose en gastos de publicidad (Feature, $x$)[cite: 130]. [cite_start]El modelo $y = wx + b$ aprende los **par谩metros** $w$ (peso) y $b$ [cite: 137] [cite_start]iterando desde valores arbitrarios ($f_1$) hasta un valor 贸ptimo ($f_3$) que minimiza el error [cite: 142-144].

#### ML y Otros Campos
[cite_start]El Machine Learning est谩 profundamente interconectado con otros campos[cite: 167]:
* [cite_start]Es un subcampo de la **Inteligencia Artificial**[cite: 160].
* [cite_start]**Deep Learning** es un subcampo del Machine Learning[cite: 163].
* [cite_start]Se solapa significativamente con **Estad铆stica**, **Miner铆a de Datos** y **Reconocimiento de Patrones**[cite: 154, 155, 159].

#### Tipos de Machine Learning
[cite_start]Seg煤n el m茅todo de supervisi贸n, el ML se divide en[cite: 197]:
1.  [cite_start]**Supervisado:** Se proporciona un patr贸n objetivo (datos etiquetados)[cite: 199, 207]. [cite_start]El cap铆tulo se centra en este tipo [cite: 244][cite_start], que incluye algoritmos como Regresi贸n Lineal, Regresi贸n Log铆stica, rboles de Decisi贸n, KNN, SVM y Redes Neuronales[cite: 244].
2.  [cite_start]**No Supervisado:** El patr贸n objetivo debe ser descubierto (datos no etiquetados)[cite: 200, 208]. [cite_start]Incluye Clustering, PCA y An谩lisis de Asociaci贸n[cite: 244].
3.  [cite_start]**Refuerzo:** Se aprende mediante la optimizaci贸n de pol铆ticas (recompensas y castigos)[cite: 206, 209].

#### Flujo de Trabajo del Machine Learning
[cite_start]El proceso general para construir un modelo de ML es[cite: 215]:
1.  [cite_start]**Definici贸n del Problema:** Comprender el objetivo de negocio[cite: 222, 225].
2.  [cite_start]**Preparaci贸n de Datos:** Recolecci贸n de datos brutos (Raw Data) [cite: 228, 231] [cite_start]y preprocesamiento[cite: 223, 226].
3.  [cite_start]**Machine Learning (Modelado):** Se divide la data en conjuntos de **Train** (Entrenamiento) [cite: 224][cite_start], **Validate** (Validaci贸n) [cite: 229] [cite_start]y **Test** (Prueba)[cite: 230].
4.  [cite_start]**Entrenamiento y Evaluaci贸n:** Esta fase incluye **Ingenier铆a de caracter铆sticas** (Feature engineering) [cite: 235][cite_start], **Modelado y optimizaci贸n** (entrenar el modelo con los datos) [cite: 236-237][cite_start], y **Evaluaci贸n de rendimiento** (Performance metrics) [cite: 238-239].
5.  [cite_start]**Aplicaci贸n:** Aplicar el modelo en la vida real[cite: 232].

#### Par谩metros vs. Hiperpar谩metros
* [cite_start]**Par谩metros:** Se aprenden *desde los datos* durante el entrenamiento[cite: 261]. [cite_start]Contienen el patr贸n de los datos [cite: 262] [cite_start](ej. $w$ y $b$ en regresi贸n lineal [cite: 263][cite_start], pesos de una red neuronal [cite: 264]).
* [cite_start]**Hiperpar谩metros:** Se configuran *manualmente* por el practicante *antes* del entrenamiento[cite: 266]. [cite_start]Se "afinan" (tunan) para optimizar el rendimiento [cite: 267] [cite_start](ej. el valor $k$ en KNN [cite: 268][cite_start], la tasa de aprendizaje [cite: 269][cite_start], la profundidad m谩xima de un 谩rbol [cite: 270]).

---

### 1.2. Biblioteca Python scikit-learn

[cite_start]`scikit-learn` es la biblioteca de ML m谩s representativa de Python[cite: 357].

#### Caracter铆sticas
* [cite_start]Proporciona una interfaz de biblioteca integrada y unificada[cite: 300].
* [cite_start]Incluye una amplia variedad de algoritmos de ML, funciones de preprocesamiento y selecci贸n de modelos[cite: 305].
* [cite_start]Es simple, eficiente y est谩 construida sobre **NumPy, SciPy y matplotlib**[cite: 307].
* [cite_start]Es de c贸digo abierto y puede usarse comercialmente[cite: 311].
* [cite_start]**No soporta GPU**[cite: 310].

#### Mecanismo de `scikit-learn`
[cite_start]El flujo de trabajo de la API de `scikit-learn` es intuitivo y sigue tres pasos[cite: 323]:
1.  [cite_start]**Instance:** Crear una instancia del objeto del modelo (Estimator)[cite: 325].
2.  [cite_start]**Fit:** Entrenar el modelo con los datos[cite: 326].
3.  [cite_start]**Predict / transform:** Usar el modelo entrenado para hacer predicciones o transformar datos[cite: 327].



#### Estimator, Classifier y Regressor
* **`Estimator`:** El objeto base. [cite_start]Aprende de los datos usando el m茅todo `.fit()` [cite: 343] [cite_start]y puede hacer predicciones usando `.predict()`[cite: 339, 343].
* [cite_start]**`Classifier`:** Un estimador para tareas de clasificaci贸n (ej. `DecisionTreeClassifier`, `KNeighborsClassifier`) [cite: 340, 344-345].
* [cite_start]**`Regressor`:** Un estimador para tareas de regresi贸n (predicci贸n num茅rica) (ej. `LinearRegression`, `KNeighborsRegressor`) [cite: 340, 346-347].

#### Sintaxis B谩sica de `scikit-learn`
* [cite_start]**Importar un estimador:** [cite: 358-359]
    [cite_start]`from sklearn.linear_model import LinearRegression` [cite: 360]
* **Importar un preprocesador:**
    [cite_start]`from sklearn.preprocessing import StandardScaler` [cite: 381]
* **Importar divisi贸n de datos:**
    [cite_start]`from sklearn.model_selection import train_test_split` [cite: 493]
* **Importar m茅tricas:**
    [cite_start]`from sklearn import metrics` [cite: 384]

* [cite_start]**Instanciar (con hiperpar谩metros):** [cite: 363]
    [cite_start]`myModel = KNeighborsClassifier(n_neighbors=10)` [cite: 364]
* [cite_start]**Dividir los datos (Hold-out):** [cite: 382]
    [cite_start]`X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)` [cite: 383]
* [cite_start]**Entrenar el modelo (Supervisado):** [cite: 378]
    `myModel.fit(X_train, Y_train)`
* [cite_start]**Hacer predicciones:** [cite: 380]
    `Y_pred = myModel.predict(X_test)`
* [cite_start]**Evaluar el rendimiento:** [cite: 384]
    `metrics.accuracy_score(Y_test, Y_pred)`
* [cite_start]**Afinar hiperpar谩metros (con Cross-Validation):** [cite: 385]
    [cite_start]`myGridCV = GridSearchCV(estimator, parameter_grid, cv=5)` [cite: 386]

#### Ejemplo Pr谩ctico: Estandarizaci贸n
[cite_start]El preprocesamiento, como la **estandarizaci贸n**, es crucial para mejorar el rendimiento[cite: 769]. [cite_start]La estandarizaci贸n (o *z-transformation*) [cite: 773] [cite_start]convierte los datos para que sigan una distribuci贸n normal est谩ndar [cite: 772][cite_start], usando la f贸rmula $z = \frac{x - m}{\sigma}$ (donde $m$ es la media y $\sigma$ la desviaci贸n est谩ndar)[cite: 776].

[cite_start]En `scikit-learn`, se usa `StandardScaler`[cite: 777]:
1.  [cite_start]**Importar:** `from sklearn.preprocessing import StandardScaler` [cite: 786, 927]
2.  [cite_start]**Instanciar:** `scaler = StandardScaler()` [cite: 787, 930]
3.  **Ajustar (Fit):** Se aprende la media ($m$) y la desviaci贸n ($\sigma$) **solo de los datos de entrenamiento**:
    [cite_start]`scaler.fit(X_train)` [cite: 837, 932]
4.  [cite_start]**Transformar:** Se aplica la transformaci贸n a los datos de entrenamiento y prueba[cite: 926]:
    [cite_start]`X_train = scaler.transform(X_train)` [cite: 839, 933]
    `X_test = scaler.transform(X_test)`
5.  [cite_start]**`fit_transform`:** Se pueden combinar los pasos 3 y 4 (solo para `X_train`)[cite: 1063]:
    `X_train = scaler.fit_transform(X_train)`

[cite_start]Antes de la estandarizaci贸n, las columnas pueden tener rangos de valores muy diferentes[cite: 880]. [cite_start]Despu茅s, todos los valores est谩n centrados alrededor de 0, lo que ayuda a muchos algoritmos a converger mejor[cite: 915].

#### [cite_start]M贸dulos Principales de `scikit-learn` [cite: 1096, 1109]

| M贸dulo | Funci贸n Principal | Ejemplos |
| :--- | :--- | :--- |
| `sklearn.datasets` | [cite_start]Cargar datasets de ejemplo[cite: 1102]. | `load_iris()`, `load_breast_cancer()` |
| `sklearn.preprocessing` | [cite_start]Preprocesamiento de datos (escalado, codificaci贸n)[cite: 1102]. | `StandardScaler`, `LabelEncoder`, `OneHotEncoder` |
| `sklearn.model_selection` | [cite_start]Divisi贸n de datos, validaci贸n y afinado de hiperpar谩metros[cite: 1102]. | `train_test_split`, `GridSearchCV`, `KFold` |
| `sklearn.metrics` | [cite_start]Evaluaci贸n de rendimiento del modelo[cite: 1102]. | `accuracy_score`, `precision_score`, `recall_score`, `roc_auc_score` |
| `sklearn.linear_model` | [cite_start]Algoritmos lineales[cite: 1110]. | `LinearRegression`, `LogisticRegression` |
| `sklearn.tree` | [cite_start]Algoritmos de rboles de Decisi贸n[cite: 1110]. | `DecisionTreeClassifier` |
| `sklearn.neighbors` | [cite_start]Algoritmos de vecinos cercanos[cite: 1110]. | `KNeighborsClassifier` (K-NN) |
| `sklearn.svm` | [cite_start]Support Vector Machine (M谩quinas de Vectores de Soporte)[cite: 1110]. | `SVC` |
| `sklearn.ensemble` | [cite_start]Algoritmos de Ensamblado (Ensemble)[cite: 1110]. | `RandomForestClassifier`, `AdaBoostClassifier` |
| `sklearn.cluster` | [cite_start]Algoritmos de clustering (No supervisado)[cite: 1110]. | `KMeans`, `DBSCAN` |
| `sklearn.pipeline` | [cite_start]Herramienta para encadenar pasos de preprocesamiento y modelado[cite: 1110]. | `Pipeline` |

---

### 1.3. Preparaci贸n y Divisi贸n del Dataset

[cite_start]La divisi贸n de datos es fundamental para evaluar un modelo de ML[cite: 1146]. [cite_start]El conjunto de datos general se divide en un conjunto de **entrenamiento** y uno de **evaluaci贸n (prueba)**[cite: 1162, 1165, 1168].

#### Overfitting (Sobreajuste) y Generalizaci贸n
* [cite_start]**Generalizaci贸n:** Es la capacidad del modelo para predecir con precisi贸n datos nuevos que no ha visto antes[cite: 1190].
* [cite_start]**Overfitting:** Ocurre cuando un modelo se ajusta *demasiado* a los datos de entrenamiento, aprendiendo incluso el ruido[cite: 1189, 1260].
* [cite_start]**Underfitting (Subajuste):** Ocurre cuando un modelo es *demasiado simple* (baja capacidad) y no puede capturar el patr贸n subyacente de los datos[cite: 1239].



> [cite_start]**El Dilema:** A medida que aumenta la complejidad (flexibilidad) del modelo[cite: 1283]:
> [cite_start]* El error en el **conjunto de entrenamiento** (Training set) siempre disminuye[cite: 1301].
> [cite_start]* El error en el **conjunto de prueba** (Test set) disminuye al principio, pero luego comienza a *aumentar*[cite: 1302]. [cite_start]El punto donde el error de prueba empieza a subir es donde comienza el overfitting[cite: 1303].

[cite_start]El conjunto de prueba es **esencial** [cite: 1305] para detectar el overfitting y seleccionar un modelo que generalice bien.

#### Cross-Validation (Validaci贸n Cruzada)
[cite_start]El conjunto de prueba (Test set) debe usarse **隆solo una vez!** al final, para la evaluaci贸n final[cite: 1320].

[cite_start]Para evaluar el modelo *durante* el entrenamiento (por ejemplo, para afinar hiperpar谩metros [cite: 1329]), necesitamos una forma de simular un "conjunto de prueba" sin tocar el real. [cite_start]Para esto, dividimos el **conjunto de entrenamiento** (Training Data) [cite: 1324] [cite_start]en dos partes m谩s peque帽as: un nuevo conjunto de `Train` [cite: 1323] [cite_start]y un conjunto de `Cross Validate` (Validaci贸n)[cite: 1322, 1325].

**M茅todo: k-Fold Cross-Validation**
[cite_start]Es el m茅todo m谩s com煤n[cite: 1383, 1387]:
1.  [cite_start]Se subdivide el conjunto de entrenamiento (original) en *k* partes iguales (folds)[cite: 1361]. [cite_start](Usualmente k=10 [cite: 1390]).
2.  [cite_start]Se itera *k* veces (rondas) [cite: 1391, 1394-1402].
3.  [cite_start]En cada ronda, se usa 1 fold como conjunto de **validaci贸n** y los *k-1* folds restantes como conjunto de **entrenamiento** [cite: 1361-1366, 1395-1419].
4.  [cite_start]Se calcula la m茅trica de rendimiento (ej. accuracy) en cada ronda [cite: 1420-1422].
5.  [cite_start]El rendimiento final del modelo es el **promedio** de las m茅tricas de las *k* rondas[cite: 1423].



**M茅todo: Leave One Out (LOO)**
[cite_start]Es un caso extremo de k-Fold donde $k$ es igual al n煤mero total de muestras[cite: 1376]. [cite_start]Se entrena con todos los datos menos uno, y se valida con ese 煤nico dato [cite: 1378-1379]. [cite_start]Es computacionalmente muy costoso[cite: 1376].

---

### 1.4. Preprocesamiento de Datos

Preparar los datos es vital para un buen modelo. [cite_start]Esto incluye la limpieza (manejo de valores at铆picos y faltantes) [cite: 1452] y la transformaci贸n (escalado y codificaci贸n).

#### Manejo de Valores Faltantes (Missing Values)
[cite_start]Los valores faltantes (identificados en Python como `np.nan` [cite: 1610] [cite_start]o `NaN` [cite: 1642]) deben ser tratados.

**1. Identificaci贸n:**
[cite_start]Se pueden contar usando `df.isnull().sum()`[cite: 1656, 1661].

**2. [cite_start]Eliminaci贸n (con Pandas `dropna()`):** [cite: 1684]
* [cite_start]`df.dropna()`: Elimina cualquier **fila** que contenga al menos un `NaN` (eje por defecto 0)[cite: 1685, 1694].
* [cite_start]`df.dropna(axis=1)`: Elimina cualquier **columna** que contenga un `NaN`[cite: 1743].
* [cite_start]`df.dropna(how='all')`: Elimina filas/columnas donde **todos** los valores son `NaN`[cite: 1759, 1794].
* [cite_start]`df.dropna(thresh=N)`: Mantiene las filas que tienen al menos `N` valores no-`NaN`[cite: 1811, 1829].
* [cite_start]`df.dropna(subset=['col_name'])`: Elimina filas que tienen `NaN` espec铆ficamente en la columna 'col\_name'[cite: 1845, 1849].

**3. Imputaci贸n (Relleno):**
[cite_start]Se usa cuando eliminar datos resultar铆a en una p茅rdida significativa de informaci贸n[cite: 1868].
* [cite_start]**M茅todos simples:** Rellenar con un valor (ej. 'unknown' [cite: 1563][cite_start]), la media, la mediana o el valor m谩s frecuente (moda) de la columna[cite: 1563, 1870].
* [cite_start]**Con `scikit-learn` (`SimpleImputer`):** Es el m茅todo preferido[cite: 1871].
    * [cite_start]`from sklearn.impute import SimpleImputer` [cite: 1872]
    * [cite_start]`impt = SimpleImputer(strategy='mean')` [cite: 1874] [cite_start](Estrategias: 'mean', 'median', 'most_frequent' [cite: 1926]).
    * [cite_start]`impt.fit(X_train)`[cite: 1912]: Aprende la media (o mediana/moda) del set de entrenamiento.
    * [cite_start]`X_train_imputed = impt.transform(X_train)`: Aplica la imputaci贸n[cite: 1915].
    * [cite_start]`X_test_imputed = impt.transform(X_test)`: Aplica la *misma* imputaci贸n (con la media de train) al set de prueba[cite: 1946].

#### Manejo de Datos Categ贸ricos
Los algoritmos de ML requieren entradas num茅ricas. [cite_start]Los datos categ贸ricos deben ser convertidos[cite: 2000].

**1. [cite_start]Datos Ordinales (con orden):** [cite: 1967]
Ej. Tallas: 'M' < 'L' < 'XL'.
[cite_start]Se deben mapear a enteros que respeten ese orden [cite: 1986-1987].
* [cite_start]`size_mapping = {'M': 1, 'L': 2, 'XL': 3}` [cite: 2001-2003]
* [cite_start]`df['size'] = df['size'].map(size_mapping)` [cite: 2029]

**2. Datos Nominales (sin orden) y Etiquetas de Clase:**
Ej. [cite_start]Colores: 'red', 'green', 'blue' [cite: 1986] o Etiquetas: 'setosa', 'versicolor'.

* **Codificaci贸n de Etiquetas (Label Encoding):**
    [cite_start]Convierte cada etiqueta 煤nica en un entero (ej. 'class1': 0, 'class2': 1)[cite: 2057]. [cite_start]Se usa `LabelEncoder` de `scikit-learn`[cite: 2120].
    * [cite_start]`from sklearn.preprocessing import LabelEncoder` [cite: 2138]
    * [cite_start]`enc = LabelEncoder()` [cite: 2139]
    * [cite_start]`y_encoded = enc.fit_transform(df['classlabel'])` [cite: 2140]

* [cite_start]**One-Hot Encoding (para caracter铆sticas nominales):** [cite: 2159]
    Usar `LabelEncoder` para caracter铆sticas (X) es incorrecto, ya que crea un orden artificial. [cite_start]Se debe usar **One-Hot Encoding**[cite: 2164].
    [cite_start]Crea nuevas columnas "dummy" (0 o 1) para cada categor铆a, indicando presencia (1) o ausencia (0) [cite: 2162-2163].
    * [cite_start]**M茅todo Pandas:** `pd.get_dummies(df['species'])` [cite: 2232-2233].
    * [cite_start]**M茅todo `scikit-learn`:** `OneHotEncoder`[cite: 2247, 2261]. [cite_start]Este m茅todo es preferido en pipelines y a menudo devuelve una **matriz dispersa** (sparse matrix) [cite: 2247-2248] para ahorrar memoria, ya que la mayor铆a de los valores ser谩n 0.

#### Divisi贸n de Datos Estratificada (Stratify)
Al usar `train_test_split`, si el dataset est谩 desbalanceado (ej. 90% clase A, 10% clase B), una divisi贸n aleatoria simple podr铆a resultar en un set de prueba sin muestras de la clase B.
* [cite_start]**Soluci贸n:** Usar el par谩metro `stratify=y`[cite: 2384].
* [cite_start]Esto asegura que la proporci贸n de las clases (ej. 90/10) se mantenga *id茅ntica* tanto en el conjunto de entrenamiento como en el de prueba, reflejando el dataset original[cite: 2384].

#### T贸picos Avanzados: Tradeoff de Sesgo-Varianza y Regularizaci贸n
* **Tradeoff de Sesgo-Varianza:**
    * [cite_start]**Sesgo (Bias):** Error por suposiciones incorrectas (Underfitting)[cite: 2388].
    * [cite_start]**Varianza (Variance):** Error por sensibilidad excesiva a los datos de entrenamiento (Overfitting)[cite: 2388].
    * **Error Total $\approx$ Sesgo虏 + Varianza**. [cite_start]El objetivo es encontrar la complejidad 贸ptima que minimice este error total[cite: 2389].
* **Regularizaci贸n:** T茅cnica para prevenir el overfitting en modelos lineales penalizando coeficientes (pesos) grandes.
    * [cite_start]**Ridge (L2):** A帽ade una penalizaci贸n $\lambda\sum{w_j^2}$[cite: 2390, 2392]. Encoge los pesos, pero no los hace cero.
    * [cite_start]**Lasso (L1):** A帽ade una penalizaci贸n $\lambda\sum{|w_j|}$[cite: 2393, 2394]. Puede forzar que algunos pesos sean exactamente cero, realizando una selecci贸n de caracter铆sticas autom谩tica.
    * [cite_start]**ElasticNet:** Combina penalizaciones L1 y L2[cite: 2395].

---

### 1.5. Pr谩ctica: Soluci贸n de Problemas con scikit-learn (Ej. Iris)

[cite_start]Esta secci贸n aplica todos los conceptos anteriores en un caso pr谩ctico completo usando el dataset "Iris"[cite: 2398].

#### 1. Entendimiento del Problema y Datos (EDA)
* [cite_start]**Objetivo:** Clasificar la especie de una flor Iris (Target)[cite: 2398].
* [cite_start]**Clases (Target):** 3 especies (Setosa, Versicolor, Virginica)[cite: 2410].
* [cite_start]**Caracter铆sticas (Features):** `sepal_length`, `sepal_width`, `petal_length`, `petal_width`[cite: 2400, 2409].
* **An谩lisis de Datos:**
    * [cite_start]Se cargan los datos y se convierten a un DataFrame de Pandas[cite: 2404].
    * **Valores Faltantes:** Se comprueba con `iris.isnull().sum()`. [cite_start]No se encontraron[cite: 2411].
    * [cite_start]**Distribuci贸n de Clases:** Se comprueba con `iris.groupby('target').size()`[cite: 2418]. [cite_start]Hay 50 muestras de cada clase (33.3% cada una)[cite: 2418, 2434]. Es un **dataset balanceado**.
    * [cite_start]**Estad铆sticas y Correlaci贸n:** `iris.describe()` [cite: 2413] [cite_start]y `iris.corr()`[cite: 2416]. [cite_start]Se observa que `petal_length` y `petal_width` est谩n altamente correlacionados (0.96) [cite: 2416][cite_start], sugiriendo un problema de multicolinealidad[cite: 2417].
    * [cite_start]**Visualizaci贸n:** Se usan `pairplot` [cite: 2429] y `heatmap` para confirmar visualmente las relaciones y la alta correlaci贸n.

#### 2. Divisi贸n y Preparaci贸n de Datos
* **Separaci贸n X/y:** Se separan las caracter铆sticas (X) del objetivo (y).
* **Divisi贸n Train/Test:** Se usa `train_test_split` (ej. 80% train, 20% test).
* **Validaci贸n Cruzada:**
    * [cite_start]Se muestra c贸mo usar `KFold` (CV est谩ndar) [cite: 2442] [cite_start]y `StratifiedKFold` (CV estratificada)[cite: 2444].
    * [cite_start]`StratifiedKFold` es preferible porque mantiene la distribuci贸n 33/33/33 de las clases en cada fold, asegurando que la validaci贸n sea representativa[cite: 2444].

#### 3. Selecci贸n y Evaluaci贸n del Modelo
* **Curva de Aprendizaje (`Learning Curve`):**
    [cite_start]Se usa para diagnosticar bias vs. variance[cite: 2450]. Muestra el rendimiento del modelo a medida que ve m谩s datos de entrenamiento.
* **Afinado de Hiperpar谩metros (`GridSearchCV`):**
    [cite_start]Se utiliza para encontrar la mejor combinaci贸n de hiperpar谩metros (ej. `criterion`, `max_depth` para un `DecisionTreeClassifier`) probando todas las combinaciones posibles mediante validaci贸n cruzada[cite: 2454].

#### 4. M茅tricas de Evaluaci贸n (Clasificaci贸n)
Una vez que el modelo (`GridSearchCV`) est谩 entrenado y se hacen predicciones sobre el `X_test`, se eval煤a el rendimiento.

* [cite_start]**Matriz de Confusi贸n (`Confusion Matrix`):** [cite: 2461]
    Es la base para todas las m茅tricas. Compara los valores reales (True label) con los predichos (Predicted label).
    * [cite_start]**TP (True Positive):** Real = 1, Predicho = 1[cite: 2463].
    * [cite_start]**FN (False Negative):** Real = 1, Predicho = 0[cite: 2463].
    * [cite_start]**FP (False Positive):** Real = 0, Predicho = 1[cite: 2463].
    * [cite_start]**TN (True Negative):** Real = 0, Predicho = 0[cite: 2463].

* **M茅tricas Clave:**
    * [cite_start]**Accuracy (Exactitud):** $\frac{TP + TN}{Total}$[cite: 2471]. Proporci贸n de predicciones correctas. (Usar con cuidado en datasets desbalanceados).
    * [cite_start]**Precision (Precisi贸n):** $\frac{TP}{TP + FP}$[cite: 2464]. De los que *dijimos* que eran positivos, 驴cu谩ntos acertamos?.
    * [cite_start]**Recall (Sensibilidad o TPR):** $\frac{TP}{TP + FN}$[cite: 2466, 2473]. De *todos los positivos reales*, 驴cu谩ntos encontramos?.
    * [cite_start]**F1-Score:** La media arm贸nica de Precision y Recall[cite: 2468]. Es una m茅trica excelente para datasets desbalanceados. [cite_start]$F_1 = 2 \frac{Precision \times Recall}{Precision + Recall}$[cite: 2468].
    * [cite_start]**FPR (Tasa de Falsos Positivos):** $\frac{FP}{FP + TN}$[cite: 2473]. Proporci贸n de negativos reales que clasificamos incorrectamente como positivos.

* **Curva ROC y AUC:**
    * **Curva ROC:** Gr谩fica que muestra el rendimiento de un clasificador en todos los umbrales de clasificaci贸n. [cite_start]Muestra **TPR** (Eje Y) vs. **FPR** (Eje X)[cite: 2475].
    * **AUC (Area Under the Curve):** El 谩rea bajo la curva ROC. Es una m茅trica 煤nica que resume el rendimiento del modelo.
        * AUC = 1.0: Clasificador perfecto.
        * [cite_start]AUC = 0.5: Clasificador in煤til (aleatorio)[cite: 2476].
        * [cite_start]Un AUC de 0.85 o m谩s se considera bueno[cite: 2476].

#### 5. Predicci贸n Final
* [cite_start]Se carga el modelo final (el mejor `estimator_` encontrado por `GridSearchCV`)[cite: 2478].
* [cite_start]Se realizan las predicciones finales sobre el conjunto de prueba (`X_test`)[cite: 2479].
* [cite_start]Los resultados se guardan, por ejemplo, en un archivo CSV[cite: 2480].

---

 **Fecha de creaci贸n:** 27/10/2025  
锔 **Autor:** Fran Garc铆a

